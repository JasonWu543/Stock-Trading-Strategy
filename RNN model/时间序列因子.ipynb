{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fcf119-4bfa-402a-8f42-7ff6c9fa31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9cb109-80a3-4f28-97fb-ffb9166d8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(folder_path):\n",
    "    \"\"\"加载股票数据并预处理\"\"\"\n",
    "    csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    stock_data = pd.concat(\n",
    "        (pd.read_csv(csv, parse_dates=['Date']) for csv in csv_files),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    stock_data = stock_data.sort_values(['Name', 'Date'])\n",
    "    return stock_data\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"数据预处理：填充缺失值\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        df[col] = df[col].fillna((df[col].ffill() + df[col].bfill()) / 2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d085c7-ddc1-48d0-af70-a66b3ea685a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15099</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>39.69</td>\n",
       "      <td>41.22</td>\n",
       "      <td>38.79</td>\n",
       "      <td>40.91</td>\n",
       "      <td>24232729</td>\n",
       "      <td>AABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15100</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>41.22</td>\n",
       "      <td>41.90</td>\n",
       "      <td>40.77</td>\n",
       "      <td>40.97</td>\n",
       "      <td>20553479</td>\n",
       "      <td>AABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15101</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>40.93</td>\n",
       "      <td>41.73</td>\n",
       "      <td>40.85</td>\n",
       "      <td>41.53</td>\n",
       "      <td>12829610</td>\n",
       "      <td>AABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>42.88</td>\n",
       "      <td>43.57</td>\n",
       "      <td>42.80</td>\n",
       "      <td>43.21</td>\n",
       "      <td>29422828</td>\n",
       "      <td>AABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15103</th>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>43.10</td>\n",
       "      <td>43.66</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.42</td>\n",
       "      <td>16268338</td>\n",
       "      <td>AABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36231</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>83.88</td>\n",
       "      <td>84.02</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.97</td>\n",
       "      <td>10161447</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36232</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>83.96</td>\n",
       "      <td>84.36</td>\n",
       "      <td>83.90</td>\n",
       "      <td>83.98</td>\n",
       "      <td>4777216</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36233</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>83.99</td>\n",
       "      <td>84.10</td>\n",
       "      <td>83.74</td>\n",
       "      <td>83.90</td>\n",
       "      <td>7000612</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36234</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>83.98</td>\n",
       "      <td>84.05</td>\n",
       "      <td>83.80</td>\n",
       "      <td>84.02</td>\n",
       "      <td>7495254</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36235</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>84.00</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.64</td>\n",
       "      <td>83.64</td>\n",
       "      <td>8523411</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93612 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Open   High    Low  Close    Volume  Name\n",
       "15099 2006-01-03  39.69  41.22  38.79  40.91  24232729  AABA\n",
       "15100 2006-01-04  41.22  41.90  40.77  40.97  20553479  AABA\n",
       "15101 2006-01-05  40.93  41.73  40.85  41.53  12829610  AABA\n",
       "15102 2006-01-06  42.88  43.57  42.80  43.21  29422828  AABA\n",
       "15103 2006-01-09  43.10  43.66  42.82  43.42  16268338  AABA\n",
       "...          ...    ...    ...    ...    ...       ...   ...\n",
       "36231 2017-12-22  83.88  84.02  83.60  83.97  10161447   XOM\n",
       "36232 2017-12-26  83.96  84.36  83.90  83.98   4777216   XOM\n",
       "36233 2017-12-27  83.99  84.10  83.74  83.90   7000612   XOM\n",
       "36234 2017-12-28  83.98  84.05  83.80  84.02   7495254   XOM\n",
       "36235 2017-12-29  84.00  84.20  83.64  83.64   8523411   XOM\n",
       "\n",
       "[93612 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_path = 'time-series-data/'\n",
    "stock_data = load_stock_data(folder_path)\n",
    "display(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c12e8a9-5ab3-4566-966f-5b84f5ae7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockRNNDataset(Dataset):\n",
    "    \"\"\"构建 PyTorch Dataset，用于时间序列窗口\"\"\"\n",
    "    def __init__(self, df, time_step=60, horizon=1, features=None):\n",
    "        self.time_step = time_step\n",
    "        self.horizon = horizon\n",
    "        self.features = features or ['Open','High','Low','Close','Volume']\n",
    "        self.scaler = StandardScaler()\n",
    "        self.data = []\n",
    "\n",
    "        for name, grp in df.groupby('Name'):\n",
    "            grp = grp.sort_values('Date').reset_index(drop=True)\n",
    "            X = grp[self.features].values\n",
    "            y = grp['Return'].shift(-horizon).values\n",
    "            if len(grp) < time_step + horizon:\n",
    "                continue\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            for i in range(len(grp) - time_step - horizon + 1):\n",
    "                X_seq = X_scaled[i:i+time_step]\n",
    "                label = 1 if y[i+time_step-1] > 0 else 0\n",
    "                self.data.append((X_seq, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_seq, y = self.data[idx]\n",
    "        return torch.FloatTensor(X_seq), torch.FloatTensor([y])\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size, device=x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        return self.sigmoid(self.fc(out))\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=10):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            pred = model(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # TODO: 在此处添加验证集评估\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_factor_scores(model, df, time_step, device):\n",
    "    model.eval()\n",
    "    records = []\n",
    "    scaler_cache = {}\n",
    "    with torch.no_grad():\n",
    "        for name, grp in df.groupby('Name'):\n",
    "            grp = grp.sort_values('Date').reset_index(drop=True)\n",
    "            feats = grp[['Open','High','Low','Close','Volume']].values\n",
    "            if len(grp) < time_step:\n",
    "                continue\n",
    "            # 缓存各股票的 scaler\n",
    "            scaler = StandardScaler().fit(feats)\n",
    "            feats_scaled = scaler.transform(feats)\n",
    "            for i in range(time_step, len(grp)):\n",
    "                X_seq = torch.FloatTensor(feats_scaled[i-time_step:i]).unsqueeze(0).to(device)\n",
    "                score = model(X_seq).item()\n",
    "                records.append({'Name': name,\n",
    "                                'Date': grp.loc[i, 'Date'],\n",
    "                                'rnn_score': score})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def backtest_and_ic(factor_df, price_df):\n",
    "    price_df = price_df.copy()\n",
    "    price_df['Return'] = price_df.groupby('Name')['Close'].pct_change().shift(-1)\n",
    "    df = factor_df.merge(price_df[['Name','Date','Return']], on=['Name','Date'])\n",
    "    ic = df.groupby('Date').apply(\n",
    "        lambda x: x['rnn_score'].corr(x['Return'], method='spearman')\n",
    "    )\n",
    "    mean_ic = ic.mean()\n",
    "    def quantile_return(x):\n",
    "        x = x.copy()\n",
    "        x['group'] = pd.qcut(x['rnn_score'], 5, labels=False)\n",
    "        return x.groupby('group')['Return'].mean()\n",
    "    group_returns = df.groupby('Date').apply(quantile_return)\n",
    "    avg_group_returns = group_returns.mean()\n",
    "    return mean_ic, avg_group_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a3dcea-4318-4105-ab39-466338f6191f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m RNNModel(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, test_loader, device)\n\u001b[1;32m     12\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m generate_factor_scores(model, train_df, time_step, device)\n\u001b[1;32m     13\u001b[0m test_scores  \u001b[38;5;241m=\u001b[39m generate_factor_scores(model, test_df,  time_step, device)\n",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     52\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m---> 54\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, y_batch)\n\u001b[1;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction\n\u001b[1;32m    699\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:3554\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3552\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "stock_data['Return'] = stock_data.groupby('Name')['Close'].pct_change()\n",
    "train_df = stock_data[(stock_data['Date'] >= '2006-01-01') & (stock_data['Date'] <= '2014-12-31')]\n",
    "test_df  = stock_data[(stock_data['Date'] >= '2015-01-01') & (stock_data['Date'] <= '2017-12-31')]\n",
    "time_step = 60\n",
    "train_ds = StockRNNDataset(train_df, time_step=time_step, horizon=1)\n",
    "test_ds  = StockRNNDataset(test_df,  time_step=time_step, horizon=1)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNModel(input_size=5, hidden_size=30, num_layers=3)\n",
    "model = train_model(model, train_loader, test_loader, device)\n",
    "train_scores = generate_factor_scores(model, train_df, time_step, device)\n",
    "test_scores  = generate_factor_scores(model, test_df,  time_step, device)\n",
    "mean_ic_train, grp_ret_train = backtest_and_ic(train_scores, train_df)\n",
    "mean_ic_test,  grp_ret_test  = backtest_and_ic(test_scores,  test_df)\n",
    "print(\"Train IC:\", mean_ic_train)\n",
    "print(\"Train Group Returns:\\n\", grp_ret_train)\n",
    "print(\"Test IC:\", mean_ic_test)\n",
    "print(\"Test Group Returns:\\n\", grp_ret_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f1123f-c1fa-4336-8049-2982a53e95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/scpx1dp11q74sp7l045c9s9m0000gn/T/ipykernel_4581/186404700.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ic_series = df.groupby('Date').apply(\n",
      "/var/folders/n3/scpx1dp11q74sp7l045c9s9m0000gn/T/ipykernel_4581/186404700.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grp_ret = df.groupby('Date').apply(quantile_return).mean()\n",
      "/var/folders/n3/scpx1dp11q74sp7l045c9s9m0000gn/T/ipykernel_4581/186404700.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ic_series = df.groupby('Date').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IC: 0.013360763567649012\n",
      "Train Group Returns:\n",
      " group\n",
      "0   -0.000035\n",
      "1    0.000306\n",
      "2    0.000647\n",
      "3    0.000751\n",
      "4    0.000920\n",
      "dtype: float64\n",
      "Test IC: 0.017110917628327685\n",
      "Test Group Returns:\n",
      " group\n",
      "0    0.000066\n",
      "1    0.000198\n",
      "2    0.000853\n",
      "3    0.000814\n",
      "4    0.000790\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/scpx1dp11q74sp7l045c9s9m0000gn/T/ipykernel_4581/186404700.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grp_ret = df.groupby('Date').apply(quantile_return).mean()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. 数据加载与预处理\n",
    "\n",
    "def load_stock_data(folder_path):\n",
    "    \"\"\"加载并预处理股票数据\"\"\"\n",
    "    csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"在路径 {folder_path} 未发现 CSV 文件\")\n",
    "    stock_data = pd.concat(\n",
    "        (pd.read_csv(csv, parse_dates=['Date']) for csv in csv_files),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    stock_data = stock_data.sort_values(['Name', 'Date']).reset_index(drop=True)\n",
    "    return stock_data\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"前向后向填充缺失值\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        df[col] = df[col].fillna((df[col].ffill() + df[col].bfill()) / 2)\n",
    "    return df\n",
    "\n",
    "# 2. Dataset 定义\n",
    "\n",
    "class StockRNNDataset(Dataset):\n",
    "    \"\"\"根据时间窗口构造训练样本\"\"\"\n",
    "    def __init__(self, df, time_step=60, horizon=1, features=None):\n",
    "        self.time_step = time_step\n",
    "        self.horizon = horizon\n",
    "        self.features = features or ['Open','High','Low','Close','Volume']\n",
    "        self.data = []\n",
    "\n",
    "        for name, grp in df.groupby('Name'):\n",
    "            grp = grp.sort_values('Date').reset_index(drop=True)\n",
    "            grp['Return'] = grp['Close'].pct_change().shift(-horizon)\n",
    "            X = grp[self.features].values\n",
    "            y = grp['Return'].values\n",
    "            if len(grp) < time_step + horizon:\n",
    "                continue\n",
    "            # 标准化\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            for i in range(len(grp) - time_step - horizon + 1):\n",
    "                seq = X_scaled[i:i+time_step]\n",
    "                label = 1 if y[i+time_step-1] > 0 else 0\n",
    "                self.data.append((seq, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, label = self.data[idx]\n",
    "        return torch.FloatTensor(seq), torch.FloatTensor([label])\n",
    "\n",
    "# 3. 模型定义（移除 Sigmoid，使用 BCEWithLogitsLoss）\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size, device=x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        # 返回 logits\n",
    "        return self.fc(out)\n",
    "\n",
    "# 4. 训练函数（使用 BCEWithLogitsLoss）\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=10):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        # 可选：在此打印 epoch loss 或加入验证评估\n",
    "    return model\n",
    "\n",
    "# 5. 因子得分生成（对 logits 取 sigmoid）\n",
    "\n",
    "def generate_factor_scores(model, df, time_step, device):\n",
    "    model.eval()\n",
    "    records = []\n",
    "    with torch.no_grad():\n",
    "        for name, grp in df.groupby('Name'):\n",
    "            grp = grp.sort_values('Date').reset_index(drop=True)\n",
    "            feats = grp[['Open','High','Low','Close','Volume']].values\n",
    "            if len(grp) < time_step:\n",
    "                continue\n",
    "            scaler = StandardScaler().fit(feats)\n",
    "            feats_scaled = scaler.transform(feats)\n",
    "            for i in range(time_step, len(grp)):\n",
    "                seq = torch.FloatTensor(feats_scaled[i-time_step:i]).unsqueeze(0).to(device)\n",
    "                logit = model(seq)\n",
    "                score = torch.sigmoid(logit).item()\n",
    "                records.append({'Name': name,\n",
    "                                'Date': grp.loc[i,'Date'],\n",
    "                                'rnn_score': score})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# 6. 回测及 IC 检验\n",
    "\n",
    "def backtest_and_ic(factor_df, price_df):\n",
    "    df = factor_df.merge(\n",
    "        price_df[['Name','Date','Close']]\n",
    "            .assign(Return=price_df.groupby('Name')['Close'].pct_change().shift(-1)),\n",
    "        on=['Name','Date']\n",
    "    )\n",
    "    ic_series = df.groupby('Date').apply(\n",
    "        lambda x: x['rnn_score'].corr(x['Return'], method='spearman')\n",
    "    )\n",
    "    mean_ic = ic_series.mean()\n",
    "    def quantile_return(x):\n",
    "        x = x.copy()\n",
    "        x['group'] = pd.qcut(x['rnn_score'], 5, labels=False)\n",
    "        return x.groupby('group')['Return'].mean()\n",
    "    grp_ret = df.groupby('Date').apply(quantile_return).mean()\n",
    "    return mean_ic, grp_ret\n",
    "\n",
    "# 7. 主流程示例\n",
    "\n",
    "def main():\n",
    "    data_folder = 'time-series-data'\n",
    "    stock_data = load_stock_data(data_folder)\n",
    "    stock_data = preprocess_data(stock_data)\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "    # 划分训练测试\n",
    "    train_df = stock_data[(stock_data['Date']<'2015-01-01')]\n",
    "    test_df  = stock_data[(stock_data['Date']>='2015-01-01')]\n",
    "    # Dataset 和 Dataloader\n",
    "    time_step = 60\n",
    "    train_ds = StockRNNDataset(train_df, time_step=time_step)\n",
    "    test_ds  = StockRNNDataset(test_df,  time_step=time_step)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=32)\n",
    "    # 模型训练与评估\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = RNNModel(input_size=5, hidden_size=30, num_layers=3)\n",
    "    model = train_model(model, train_loader, test_loader, device)\n",
    "    # 因子得分 & 回测\n",
    "    train_scores = generate_factor_scores(model, train_df, time_step, device)\n",
    "    test_scores  = generate_factor_scores(model, test_df,  time_step, device)\n",
    "    ic_train, ret_train = backtest_and_ic(train_scores, train_df)\n",
    "    ic_test,  ret_test  = backtest_and_ic(test_scores,  test_df)\n",
    "    print(\"Train IC:\", ic_train)\n",
    "    print(\"Train Group Returns:\\n\", ret_train)\n",
    "    print(\"Test IC:\", ic_test)\n",
    "    print(\"Test Group Returns:\\n\", ret_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d0ea82-4c10-4f78-93aa-e7666dbb5494",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# --- 如果你在 main() 里已经得到了这几项，就直接调用： ---\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m plot_cum_nav(train_scores, train_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m训练集\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m plot_cum_nav(test_scores,  test_df,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m测试集\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_scores' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cum_nav(factor_df, price_df, title):\n",
    "    # 1. 合并收益\n",
    "    df = factor_df.merge(\n",
    "        price_df[['Name','Date','Close']]\n",
    "                .assign(Return=price_df.groupby('Name')['Close']\n",
    "                                     .pct_change().shift(-1)),\n",
    "        on=['Name','Date']\n",
    "    )\n",
    "    # 2. 分层\n",
    "    df['group'] = pd.qcut(df['score'], 5, labels=False)\n",
    "    # 3. 日度分层平均收益\n",
    "    daily = (df\n",
    "             .groupby(['Date','group'])['Return']\n",
    "             .mean()\n",
    "             .unstack()      # shape = (n_days, 5)\n",
    "             .sort_index())\n",
    "    # 4. 累积净值\n",
    "    cum_nav = (1 + daily).cumprod()\n",
    "    # 5. 绘图\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for grp in cum_nav.columns:\n",
    "        plt.plot(cum_nav.index, cum_nav[grp], label=f'组{grp+1}')\n",
    "    plt.title(f'{title}：RNN 因子分层组合累积净值')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative NAV')\n",
    "    plt.legend(title='分层')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 如果你在 main() 里已经得到了这几项，就直接调用： ---\n",
    "plot_cum_nav(train_scores, train_df, '训练集')\n",
    "plot_cum_nav(test_scores,  test_df,  '测试集')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
